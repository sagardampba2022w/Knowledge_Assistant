{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e23da56-9f1f-4bd9-adcd-c7e02d7565d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3578a32-750b-43ed-8666-047327f4212d",
   "metadata": {},
   "source": [
    "# Loading Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d375600d-1a38-4d8d-a00c-aa22fafec00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': 'General Information',\n",
       " 'Question': 'What is syndicated research?',\n",
       " 'Answer': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.',\n",
       " 'doc_id': '3e72e1c8'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Update the file path to the JSON file\n",
    "file_path = \"/workspaces/Rag_Project_Pod/Data_prep/final_data.json\"\n",
    "\n",
    "# Load the JSON file into a dictionary\n",
    "with open(file_path, 'r') as json_file:\n",
    "    documents = json.load(json_file)\n",
    "\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f4648-18b8-4a89-bdf8-2cfa4184ef03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7004976-3250-409f-8ee2-a3f71c868b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e0ff36-7668-41cd-8621-71418f4ed5b3",
   "metadata": {},
   "source": [
    "# Loading Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f80ac3-ff55-4e76-b094-3fc0fd096f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Category</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question             Category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "   Document  \n",
       "0  3e72e1c8  \n",
       "1  3e72e1c8  \n",
       "2  3e72e1c8  \n",
       "3  3e72e1c8  \n",
       "4  3e72e1c8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv(r'/workspaces/Rag_Project_Pod/Data_prep/ground_truth_data.csv')\n",
    "df_ground_truth.head()                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9771e1b9-ac0b-41c8-9411-b60a0d23eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Can you explain what syndicated research entails?',\n",
       " 'Category': 'General Information',\n",
       " 'Document': '3e72e1c8'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71105ff9-629a-4a17-9256-7acdb70bbc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx = {d['doc_id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1807ad4-5171-41bf-861f-d1d114e1bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx['3e72e1c8']['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77474f3-4a5f-45ad-a15c-fe75e3f0f16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be49ebd-d82e-4501-a6fa-29e6824488aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "150faf7d-0b31-4af7-a539-84d552236e50",
   "metadata": {},
   "source": [
    "# Index data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e86d72-d2b4-4614-acb1-e1430774faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9fa184-38a4-451f-8a9f-83bff0224733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'insights-questions'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"Answer\": {\"type\": \"text\"},\n",
    "            \"Category\": {\"type\": \"text\"},\n",
    "            \"Question\": {\"type\": \"text\"},\n",
    "            \"doc_id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"insights-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df65abf-6514-4767-a709-32eef3586643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3df0c141c145feb9f221ffaac20144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    question = doc['Question']\n",
    "    text = doc['Answer']\n",
    "    qt = question + ' ' + text\n",
    "\n",
    "    doc['question_vector'] = model.encode(question)\n",
    "    doc['text_vector'] = model.encode(text)\n",
    "    doc['question_text_vector'] = model.encode(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b32a7b-25bb-4356-8dd0-1597ac5bbf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3676b7a0e9452db62114cd4199aca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b7315-4f87-405d-99fb-72a6ecbd9595",
   "metadata": {},
   "source": [
    "# Retrieval using Hybrid Search & RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e843047f-ec46-4880-8086-5a3ffc40d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rrf(rank, k=60):\n",
    "    \"\"\" Our own implementation of the relevance score \"\"\"\n",
    "    return 1 / (k + rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22703fb-5331-4452-b154-fd6cead98694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid_rrf(field, query, vector, k=60):\n",
    "    # KNN Query\n",
    "    knn_query = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    # Keyword Query\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"Question\", \"Answer\", \"Category\"],  # Updated fields\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # KNN Search\n",
    "    knn_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"knn\": knn_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    # Keyword Search\n",
    "    keyword_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"query\": keyword_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    # Reciprocal Rank Fusion (RRF) scoring\n",
    "    rrf_scores = {}\n",
    "    \n",
    "    # Calculate RRF scores for KNN results\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Calculate RRF scores for keyword results\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-K documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = es_client.get(index=index_name, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dafda7e-347b-4481-895d-c1a2ba1e505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_hybrid_rrf(q):\n",
    "    question = q['Question']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_hybrid_rrf('question_text_vector', question, v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b742806-5eff-4036-98eb-67eed78636ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The consumer panel consists of approximately 10,000 households, representing diverse demographic and geographic segments to ensure the data is reflective of the broader population.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'Question': \"What is the sample size?\"}\n",
    "search_results = question_text_hybrid_rrf(query)\n",
    "search_results[0]['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773da1b6-2b88-4785-92cb-ca7f64da0d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4497f-a2e6-4fb6-87b9-9bbddfa7df1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77fb946-6eb5-4c18-821b-8306a45ef292",
   "metadata": {},
   "source": [
    "# The RAG flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d1f81be-974e-4559-96f4-1e90fc11eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a syndicated market research provider. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['Category']}\\nquestion: {doc['Question']}\\nanswer: {doc['Answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19ff8e2-f3ed-4302-98d9-16c5bbff5eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're a syndicated market research provider. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: What is the sample size?\\n\\nCONTEXT: \\nsection: Data Collection Methodology\\nquestion: What is the sample size of the consumer panel?\\nanswer: The consumer panel consists of approximately 10,000 households, representing diverse demographic and geographic segments to ensure the data is reflective of the broader population.\\n\\nsection: General Information\\nquestion: What is the sample size for global studies?\\nanswer: For global studies, the sample size typically includes over 50,000 respondents, ensuring a representative sample across different regions and demographics.\\n\\nsection: Data Collection Methodology\\nquestion: How is household size factored into the research?\\nanswer: Household size is factored into the research by segmenting data to understand how family size influences purchase behavior, product preferences, and shopping frequency.\\n\\nsection: Data Collection Methodology\\nquestion: What demographic data is included in the research?\\nanswer: The research includes demographic data such as age, gender, income level, education, household size, and geographic location, allowing for detailed segmentation and analysis.\\n\\nsection: Subscription and Pricing\\nquestion: Is there a trial period available?\\nanswer: Yes, we offer a 30-day trial period for new clients to: Explore the Platform (get familiar with the features and data available) and Assess the Value (determine how the data can benefit your business).\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = build_prompt(query['Question'], search_results)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77880d50-118a-4148-920d-5d562f74c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9fd018e-d0fc-46d0-98d4-730961b069c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query: dict, model='gpt-4o-mini') -> str:\n",
    "    search_results = question_text_hybrid_rrf(query)\n",
    "    prompt = build_prompt(query['Question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e58ee56d-e88a-4261-9386-2ec9cfb438db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Are quarterly summaries included with the monthly updates?',\n",
       " 'Category': 'General Information',\n",
       " 'Document': '7a6f8a30'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c313d71f-595f-4133-9578-9877263ed4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, quarterly summaries are available as part of the data updates, which are typically done on a monthly basis.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(ground_truth[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb921f15-6fde-4371-8adc-184b8401d87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The data is typically updated on a monthly basis, with quarterly and annual summaries available. Real-time or weekly updates may also be available depending on the subscription level.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx['7a6f8a30']['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca17b68-f7c9-4d38-a4fc-9369dcde1fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7707d-637e-4df6-8eab-dba10e429932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5d9529-e65d-4630-b8a5-3545cf0bae26",
   "metadata": {},
   "source": [
    "# LLM as a judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405aff9",
   "metadata": {},
   "source": [
    "# Eval using AQA only ---checking relevance of LLM Answer against the question & original answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7185b3ad-cd05-4166-83fc-4c1f4fac5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0fef1-fc1e-4cbb-9b01-673ed4ac14b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0e2fcb5-d9e3-43fe-bf8d-4480df1e4913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.998721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syndicated research includes data and findings...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.786594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The findings for syndicated research are compi...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.792197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syndicated research is commonly used in indust...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.834927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syndicated research benefits multiple clients ...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.801818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  Syndicated research is a type of market resear...   \n",
       "1  Syndicated research includes data and findings...   \n",
       "2  The findings for syndicated research are compi...   \n",
       "3  Syndicated research is commonly used in indust...   \n",
       "4  Syndicated research benefits multiple clients ...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "1  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "2  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "3  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "4  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "\n",
       "                                            question             category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "     cosine  \n",
       "0  0.998721  \n",
       "1  0.786594  \n",
       "2  0.792197  \n",
       "3  0.834927  \n",
       "4  0.801818  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-gpt4o-cosine.csv'\n",
    "df_gpt4o = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df_gpt4o.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c3b3374-485c-48c8-8947-049ad956d244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG (Fast-Moving Consumer Goods) categories.',\n",
       " 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.',\n",
       " 'document': '3e72e1c8',\n",
       " 'question': 'Can you explain what syndicated research entails?',\n",
       " 'category': 'General Information',\n",
       " 'cosine': 0.9987208}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = df_gpt4o.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c926d90-59d8-4dff-9fc7-3abc614d3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "Generated Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG (Fast-Moving Consumer Goods) categories.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05fc9ba8-4525-4f4d-8bb7-89c4732cb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16d45404-0bff-42de-a183-472f947b67ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\": \"The generated answer is identical to the original answer, providing a full and accurate explanation of what syndicated research is. It addresses the question directly and thoroughly.\"\\n}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c44346a5-7a3a-44e5-8d22-43930818c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4896d016e06468fbe74c47a0a1abcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ed59497-8d40-4ec2-b63f-a7ad15273026",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 4 column 1 (char 323)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m json_evaluations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, str_eval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(evaluations):\n\u001b[0;32m----> 4\u001b[0m     json_eval \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     json_evaluations\u001b[38;5;241m.\u001b[39mappend(json_eval)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 4 column 1 (char 323)"
     ]
    }
   ],
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dd39764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c221e367-3421-4c9d-8f60-e397e87d7b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           1059\n",
       "PARTLY_RELEVANT     237\n",
       "NON_RELEVANT          4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations = pd.DataFrame(json_evaluations)\n",
    "df_evaluations.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "554792b6-7cbf-4dde-90d7-6098e30ed78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer fails to address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses how frequently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the core...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "93   NON_RELEVANT  The generated answer fails to address the ques...\n",
       "234  NON_RELEVANT  The generated answer addresses how frequently ...\n",
       "644  NON_RELEVANT  The generated answer addresses a different que...\n",
       "983  NON_RELEVANT  The generated answer does not address the core..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations[df_evaluations.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e2643e-1ee2-4e14-b27e-7a9913abb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-aqa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e571f2",
   "metadata": {},
   "source": [
    "# Eval using QA only --- checking relevance of Answer against the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5ac5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0213087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Can I convert reports into PDF for easy distribution?\n",
      "Generated Answer: Yes, you can convert reports into PDF for easy distribution by selecting the export option in the portal's report viewer. This will allow you to create print-ready documents for sharing insights with stakeholders or integrating them into your presentations.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b9153ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer directly addresses the question by confirming that reports can be converted into PDF for distribution and provides a method for doing so, specifically mentioning the export option in the portal's report viewer. This information is pertinent and useful for the user's request.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edc66da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0106e5ca6e65495c9f4edc828fc26d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_2 = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt2_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_2.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60172f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations_2 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_2):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations_2.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bfe33f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           1233\n",
       "PARTLY_RELEVANT      64\n",
       "NON_RELEVANT          3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_2 = pd.DataFrame(json_evaluations_2)\n",
    "df_evaluations_2.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80a953bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-qa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98748b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer states that there is no s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer states that the provided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not directly address...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "93   NON_RELEVANT  The generated answer states that there is no s...\n",
       "189  NON_RELEVANT  The generated answer states that the provided ...\n",
       "983  NON_RELEVANT  The generated answer does not directly address..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_2[df_evaluations_2.Relevance == 'NON_RELEVANT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95adebb-e632-4f49-bee7-dc094ed29eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d466d-b0e7-4552-8607-897a5a70e1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
