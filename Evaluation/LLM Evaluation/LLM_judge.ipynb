{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e23da56-9f1f-4bd9-adcd-c7e02d7565d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "import groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3578a32-750b-43ed-8666-047327f4212d",
   "metadata": {},
   "source": [
    "# Loading Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d375600d-1a38-4d8d-a00c-aa22fafec00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': 'General Information',\n",
       " 'Question': 'What is syndicated research?',\n",
       " 'Answer': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.',\n",
       " 'doc_id': '3e72e1c8'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Update the file path to the JSON file\n",
    "file_path = \"/workspaces/Rag_Project_Pod/Data_prep/final_data.json\"\n",
    "\n",
    "# Load the JSON file into a dictionary\n",
    "with open(file_path, 'r') as json_file:\n",
    "    documents = json.load(json_file)\n",
    "\n",
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f4648-18b8-4a89-bdf8-2cfa4184ef03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7004976-3250-409f-8ee2-a3f71c868b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17e0ff36-7668-41cd-8621-71418f4ed5b3",
   "metadata": {},
   "source": [
    "# Loading Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f80ac3-ff55-4e76-b094-3fc0fd096f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Category</th>\n",
       "      <th>Document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>3e72e1c8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question             Category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "   Document  \n",
       "0  3e72e1c8  \n",
       "1  3e72e1c8  \n",
       "2  3e72e1c8  \n",
       "3  3e72e1c8  \n",
       "4  3e72e1c8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ground_truth = pd.read_csv(r'/workspaces/Rag_Project_Pod/Data_prep/ground_truth_data.csv')\n",
    "df_ground_truth.head()                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9771e1b9-ac0b-41c8-9411-b60a0d23eaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Can you explain what syndicated research entails?',\n",
       " 'Category': 'General Information',\n",
       " 'Document': '3e72e1c8'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71105ff9-629a-4a17-9256-7acdb70bbc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx = {d['doc_id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1807ad4-5171-41bf-861f-d1d114e1bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx['3e72e1c8']['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77474f3-4a5f-45ad-a15c-fe75e3f0f16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be49ebd-d82e-4501-a6fa-29e6824488aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "150faf7d-0b31-4af7-a539-84d552236e50",
   "metadata": {},
   "source": [
    "# Index data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05e86d72-d2b4-4614-acb1-e1430774faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9fa184-38a4-451f-8a9f-83bff0224733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'insights-questions'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"Answer\": {\"type\": \"text\"},\n",
    "            \"Category\": {\"type\": \"text\"},\n",
    "            \"Question\": {\"type\": \"text\"},\n",
    "            \"doc_id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"insights-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df65abf-6514-4767-a709-32eef3586643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ba517af10e48feb8cd9c7e2f92e6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    question = doc['Question']\n",
    "    text = doc['Answer']\n",
    "    qt = question + ' ' + text\n",
    "\n",
    "    doc['question_vector'] = model.encode(question)\n",
    "    doc['text_vector'] = model.encode(text)\n",
    "    doc['question_text_vector'] = model.encode(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b32a7b-25bb-4356-8dd0-1597ac5bbf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ef9db8ad0d40178a5be857b4c86458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0b7315-4f87-405d-99fb-72a6ecbd9595",
   "metadata": {},
   "source": [
    "# Retrieval using Hybrid Search & RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e843047f-ec46-4880-8086-5a3ffc40d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rrf(rank, k=60):\n",
    "    \"\"\" Our own implementation of the relevance score \"\"\"\n",
    "    return 1 / (k + rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22703fb-5331-4452-b154-fd6cead98694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid_rrf(field, query, vector, k=60):\n",
    "    # KNN Query\n",
    "    knn_query = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5\n",
    "    }\n",
    "\n",
    "    # Keyword Query\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"Question\", \"Answer\", \"Category\"],  # Updated fields\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # KNN Search\n",
    "    knn_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"knn\": knn_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    # Keyword Search\n",
    "    keyword_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"query\": keyword_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    \n",
    "    # Reciprocal Rank Fusion (RRF) scoring\n",
    "    rrf_scores = {}\n",
    "    \n",
    "    # Calculate RRF scores for KNN results\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Calculate RRF scores for keyword results\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-K documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = es_client.get(index=index_name, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dafda7e-347b-4481-895d-c1a2ba1e505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_hybrid_rrf(q):\n",
    "    question = q['Question']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_hybrid_rrf('question_text_vector', question, v_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b742806-5eff-4036-98eb-67eed78636ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The consumer panel consists of approximately 10,000 households, representing diverse demographic and geographic segments to ensure the data is reflective of the broader population.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'Question': \"What is the sample size?\"}\n",
    "search_results = question_text_hybrid_rrf(query)\n",
    "search_results[0]['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773da1b6-2b88-4785-92cb-ca7f64da0d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4497f-a2e6-4fb6-87b9-9bbddfa7df1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77fb946-6eb5-4c18-821b-8306a45ef292",
   "metadata": {},
   "source": [
    "# The RAG flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1f81be-974e-4559-96f4-1e90fc11eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a syndicated market research provider. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['Category']}\\nquestion: {doc['Question']}\\nanswer: {doc['Answer']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b19ff8e2-f3ed-4302-98d9-16c5bbff5eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're a syndicated market research provider. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: What is the sample size?\\n\\nCONTEXT: \\nsection: Data Collection Methodology\\nquestion: What is the sample size of the consumer panel?\\nanswer: The consumer panel consists of approximately 10,000 households, representing diverse demographic and geographic segments to ensure the data is reflective of the broader population.\\n\\nsection: General Information\\nquestion: What is the sample size for global studies?\\nanswer: For global studies, the sample size typically includes over 50,000 respondents, ensuring a representative sample across different regions and demographics.\\n\\nsection: Data Collection Methodology\\nquestion: How is household size factored into the research?\\nanswer: Household size is factored into the research by segmenting data to understand how family size influences purchase behavior, product preferences, and shopping frequency.\\n\\nsection: Data Collection Methodology\\nquestion: What demographic data is included in the research?\\nanswer: The research includes demographic data such as age, gender, income level, education, household size, and geographic location, allowing for detailed segmentation and analysis.\\n\\nsection: Subscription and Pricing\\nquestion: Is there a trial period available?\\nanswer: Yes, we offer a 30-day trial period for new clients to: Explore the Platform (get familiar with the features and data available) and Assess the Value (determine how the data can benefit your business).\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = build_prompt(query['Question'], search_results)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77880d50-118a-4148-920d-5d562f74c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "386a9f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are a crucial component in various natural language processing (NLP) applications, and their importance cannot be overstated. Here are some reasons why:\n",
      "\n",
      "1. **Real-time interactions**: Fast language models enable real-time interactions between humans and machines, which is essential for applications like chatbots, virtual assistants, and language translation systems. These models can respond quickly to user input, providing a seamless experience.\n",
      "2. **Low latency**: Fast models reduce the latency between input and response, making them suitable for applications that require instant feedback, such as speech recognition, sentiment analysis, and text summarization.\n",
      "3. **Improved user experience**: Fast language models can process and respond to user input quickly, leading to higher user satisfaction and engagement. This is particularly important in applications like customer service, where swift responses can resolve issues efficiently.\n",
      "4. **Scalability**: Fast language models can handle large volumes of data and user requests, making them scalable and suitable for large-scale applications, such as enterprise chatbots, social media analytics, and language translation platforms.\n",
      "5. **Efficient processing of large datasets**: Fast language models can process large datasets quickly, which is essential for applications like text classification, named entity recognition, and part-of-speech tagging.\n",
      "6. **Embedded systems and IoT devices**: Fast language models are necessary for embedded systems and IoT devices, which often have limited computational resources and require efficient processing of language inputs.\n",
      "7. **Conversational AI**: Fast language models are a fundamental component of conversational AI systems, which aim to enable humans to interact with machines using natural language.\n",
      "8. **Multilingual support**: Fast language models can support multiple languages, making them suitable for global applications and enabling communication across language barriers.\n",
      "9. **Improved accuracy**: Fast language models can achieve high accuracy levels, which is critical in applications like healthcare, finance, and law, where accurate language understanding is paramount.\n",
      "10. **Cost-effectiveness**: Fast language models can reduce computational costs and energy consumption, making them a cost-effective solution for large-scale NLP applications.\n",
      "\n",
      "To achieve fast language models, researchers and developers focus on various techniques, such as:\n",
      "\n",
      "1. **Model pruning**: Reducing the size and complexity of language models to improve their computational efficiency.\n",
      "2. **Knowledge distillation**: Transferring knowledge from larger, pre-trained models to smaller, faster models.\n",
      "3. **Efficient architectures**: Designing novel architectures that prioritize speed and efficiency while maintaining accuracy.\n",
      "4. **Quantization**: Representing model weights and activations using fewer bits to reduce computational requirements.\n",
      "5. **Hardware acceleration**: Leveraging specialized hardware, such as GPUs or TPUs, to accelerate language model inference.\n",
      "\n",
      "In summary, fast language models are essential for building scalable, efficient, and accurate NLP applications that can support real-time interactions, process large datasets, and provide a seamless user experience.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Groq client using the API key\n",
    "client_groq = Groq(api_key='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')\n",
    "\n",
    "# Define the function to use Groq's LLM\n",
    "def llm_groq(prompt, model='llama3-70b-8192'):  # Adjust the model name if needed\n",
    "    response = client_groq.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage:\n",
    "result = llm_groq(\"Explain the importance of fast language models\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9fd018e-d0fc-46d0-98d4-730961b069c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query: dict, model='gpt-4o-mini') -> str:\n",
    "    search_results = question_text_hybrid_rrf(query)\n",
    "    prompt = build_prompt(query['Question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e58ee56d-e88a-4261-9386-2ec9cfb438db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Are quarterly summaries included with the monthly updates?',\n",
       " 'Category': 'General Information',\n",
       " 'Document': '7a6f8a30'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c313d71f-595f-4133-9578-9877263ed4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, quarterly summaries are available as part of the data updates, which are typically done on a monthly basis.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(ground_truth[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb921f15-6fde-4371-8adc-184b8401d87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The data is typically updated on a monthly basis, with quarterly and annual summaries available. Real-time or weekly updates may also be available depending on the subscription level.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx['7a6f8a30']['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca17b68-f7c9-4d38-a4fc-9369dcde1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_groq(query: dict, model='llama3-70b-8192') -> str:\n",
    "    search_results = question_text_hybrid_rrf(query)\n",
    "    prompt = build_prompt(query['Question'], search_results)\n",
    "    answer = llm_groq(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49d7707d-637e-4df6-8eab-dba10e429932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided CONTEXT, the answer to the QUESTION is:\\n\\nNo, quarterly summaries are not included with the monthly updates. According to the CONTEXT, quarterly summaries are available, but they are not explicitly mentioned as being included with the monthly updates. The monthly updates are provided on a regular basis, and quarterly summaries are offered as an additional option.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_groq(ground_truth[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d9529-e65d-4630-b8a5-3545cf0bae26",
   "metadata": {},
   "source": [
    "# LLM as a judge\n",
    "\n",
    "\n",
    "* Evaluates responses of various LLM's using LLM(gpt 4o mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405aff9",
   "metadata": {},
   "source": [
    "### Eval using AQA only ---checking relevance of LLM Answer against the question & original answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7185b3ad-cd05-4166-83fc-4c1f4fac5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0fef1-fc1e-4cbb-9b01-673ed4ac14b4",
   "metadata": {},
   "source": [
    "### Eval gpt 4o responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0e2fcb5-d9e3-43fe-bf8d-4480df1e4913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.998721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Syndicated research includes data and findings...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.786594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The findings for syndicated research are compi...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.792197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syndicated research is commonly used in indust...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.834927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syndicated research benefits multiple clients ...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.801818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  Syndicated research is a type of market resear...   \n",
       "1  Syndicated research includes data and findings...   \n",
       "2  The findings for syndicated research are compi...   \n",
       "3  Syndicated research is commonly used in indust...   \n",
       "4  Syndicated research benefits multiple clients ...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "1  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "2  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "3  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "4  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "\n",
       "                                            question             category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "     cosine  \n",
       "0  0.998721  \n",
       "1  0.786594  \n",
       "2  0.792197  \n",
       "3  0.834927  \n",
       "4  0.801818  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-gpt4o-cosine.csv'\n",
    "df_gpt4o = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df_gpt4o.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c3b3374-485c-48c8-8947-049ad956d244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG (Fast-Moving Consumer Goods) categories.',\n",
       " 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.',\n",
       " 'document': '3e72e1c8',\n",
       " 'question': 'Can you explain what syndicated research entails?',\n",
       " 'category': 'General Information',\n",
       " 'cosine': 0.9987208}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = df_gpt4o.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0ad57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c926d90-59d8-4dff-9fc7-3abc614d3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "Generated Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG (Fast-Moving Consumer Goods) categories.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05fc9ba8-4525-4f4d-8bb7-89c4732cb047",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16d45404-0bff-42de-a183-472f947b67ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\": \"The generated answer is identical to the original answer, providing a full and accurate explanation of what syndicated research is. It addresses the question directly and thoroughly.\"\\n}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c44346a5-7a3a-44e5-8d22-43930818c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4896d016e06468fbe74c47a0a1abcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed59497-8d40-4ec2-b63f-a7ad15273026",
   "metadata": {},
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dd39764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c221e367-3421-4c9d-8f60-e397e87d7b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           1059\n",
       "PARTLY_RELEVANT     237\n",
       "NON_RELEVANT          4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations = pd.DataFrame(json_evaluations)\n",
    "df_evaluations.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "554792b6-7cbf-4dde-90d7-6098e30ed78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer fails to address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses how frequently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the core...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "93   NON_RELEVANT  The generated answer fails to address the ques...\n",
       "234  NON_RELEVANT  The generated answer addresses how frequently ...\n",
       "644  NON_RELEVANT  The generated answer addresses a different que...\n",
       "983  NON_RELEVANT  The generated answer does not address the core..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations[df_evaluations.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e2643e-1ee2-4e14-b27e-7a9913abb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-gpt4o-aqa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f47df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d6ad59f",
   "metadata": {},
   "source": [
    "### Eval gpt 3.5 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "925ed471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Syndicated research entails a type of market r...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.980938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The type of data included in syndicated resear...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.716210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The findings for syndicated research are compi...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.792197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syndicated research is commonly used in indust...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.796671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Syndicated research can benefit multiple clien...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.836032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  Syndicated research entails a type of market r...   \n",
       "1  The type of data included in syndicated resear...   \n",
       "2  The findings for syndicated research are compi...   \n",
       "3  Syndicated research is commonly used in indust...   \n",
       "4  Syndicated research can benefit multiple clien...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "1  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "2  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "3  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "4  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "\n",
       "                                            question             category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "     cosine  \n",
       "0  0.980938  \n",
       "1  0.716210  \n",
       "2  0.792197  \n",
       "3  0.796671  \n",
       "4  0.836032  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-gpt35-cosine.csv'\n",
    "df_gpt35 = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df_gpt35.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e499cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f62e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Syndicated research entails a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'document': '3e72e1c8', 'question': 'Can you explain what syndicated research entails?', 'category': 'General Information', 'cosine': 0.9809381}\n",
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "Generated Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Syndicated research entails a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer is a direct response to the question about what syndicated research entails and matches the original answer perfectly in terms of content and context.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "samples = df_gpt35.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "print(record)\n",
    "\n",
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "answer = llm(prompt, model='gpt-4o-mini')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a5319bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602a4503c69d462c82e5451e79628962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "evaluations_gpt35 = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_gpt35.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8142e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations_gpt35 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_gpt35):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations_gpt35.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d781b8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           945\n",
       "PARTLY_RELEVANT    332\n",
       "NON_RELEVANT        23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_gpt35 = pd.DataFrame(json_evaluations_gpt35)\n",
    "df_evaluations_gpt35.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6129d182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not directly address...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer focuses on geolocation da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses the frequency o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer discusses consumer behavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not relate directly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer focuses on tracking produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer directly contradicts the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer focuses on the accessibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer contradicts the original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer incorrectly states that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer directly contradicts the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer contradicts the original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer contradicts the original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer contradicts the original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer discusses the refund poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different asp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer contradicts the original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer discusses visualization t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the orig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer directly addresses a diff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Relevance                                        Explanation\n",
       "32    NON_RELEVANT  The generated answer does not address the spec...\n",
       "165   NON_RELEVANT  The generated answer does not directly address...\n",
       "220   NON_RELEVANT  The generated answer does not address the spec...\n",
       "231   NON_RELEVANT  The generated answer focuses on geolocation da...\n",
       "234   NON_RELEVANT  The generated answer addresses the frequency o...\n",
       "266   NON_RELEVANT  The generated answer discusses consumer behavi...\n",
       "369   NON_RELEVANT  The generated answer does not relate directly ...\n",
       "496   NON_RELEVANT  The generated answer focuses on tracking produ...\n",
       "536   NON_RELEVANT  The generated answer does not address the spec...\n",
       "573   NON_RELEVANT  The generated answer directly contradicts the ...\n",
       "644   NON_RELEVANT  The generated answer focuses on the accessibil...\n",
       "772   NON_RELEVANT  The generated answer contradicts the original ...\n",
       "776   NON_RELEVANT  The generated answer incorrectly states that t...\n",
       "816   NON_RELEVANT  The generated answer directly contradicts the ...\n",
       "838   NON_RELEVANT  The generated answer contradicts the original ...\n",
       "843   NON_RELEVANT  The generated answer contradicts the original ...\n",
       "863   NON_RELEVANT  The generated answer contradicts the original ...\n",
       "926   NON_RELEVANT  The generated answer discusses the refund poli...\n",
       "938   NON_RELEVANT  The generated answer addresses a different asp...\n",
       "939   NON_RELEVANT  The generated answer contradicts the original ...\n",
       "982   NON_RELEVANT  The generated answer discusses visualization t...\n",
       "983   NON_RELEVANT  The generated answer does not address the orig...\n",
       "1224  NON_RELEVANT  The generated answer directly addresses a diff..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_gpt35[df_evaluations_gpt35.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c83fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_gpt35.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-gpt35-aqa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d823c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "757361c8",
   "metadata": {},
   "source": [
    "### Eval llama 8b responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af340fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the provided context, syndicated rese...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.907631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the CONTEXT from the FAQ database, th...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.739555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the provided CONTEXT, the answer to t...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.617875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the CONTEXT, syndicated market resear...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.807952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the CONTEXT, syndicated research can ...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.790096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  Based on the provided context, syndicated rese...   \n",
       "1  Based on the CONTEXT from the FAQ database, th...   \n",
       "2  Based on the provided CONTEXT, the answer to t...   \n",
       "3  Based on the CONTEXT, syndicated market resear...   \n",
       "4  Based on the CONTEXT, syndicated research can ...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "1  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "2  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "3  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "4  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "\n",
       "                                            question             category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "     cosine  \n",
       "0  0.907631  \n",
       "1  0.739555  \n",
       "2  0.617875  \n",
       "3  0.807952  \n",
       "4  0.790096  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-llama8b-cosine.csv'\n",
    "df_llama8b = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df_llama8b.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9be3935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Based on the provided context, syndicated research entails a research agency collecting and compiling data and findings, which are then sold to multiple clients, providing insights into consumer behavior, market trends, and product performance across various FMCG categories. In contrast, custom research is tailored to the specific needs of one client, delivering specific answers to particular business questions.', 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'document': '3e72e1c8', 'question': 'Can you explain what syndicated research entails?', 'category': 'General Information', 'cosine': 0.9076309}\n",
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "Generated Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Based on the provided context, syndicated research entails a research agency collecting and compiling data and findings, which are then sold to multiple clients, providing insights into consumer behavior, market trends, and product performance across various FMCG categories. In contrast, custom research is tailored to the specific needs of one client, delivering specific answers to particular business questions.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer accurately summarizes the key aspects of syndicated research described in the original answer, including the role of the research agency and the nature of the insights provided. It also appropriately contrasts syndicated research with custom research, which adds context without diverging from the original topic.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "samples = df_llama8b.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "print(record)\n",
    "\n",
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "answer = llm(prompt, model='gpt-4o-mini')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87111ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5c71e69e444892b69eac3d44630657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "evaluations_llama8b = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_llama8b.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d574e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations_llama8b = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_llama8b):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations_llama8b.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fde4c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           987\n",
       "PARTLY_RELEVANT    305\n",
       "NON_RELEVANT         8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_llama8b = pd.DataFrame(json_evaluations_llama8b)\n",
    "df_evaluations_llama8b.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88f3592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer lists channels that are n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The original answer discusses how brand loyalt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer lists types of consumer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer incorrectly states that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the quer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer incorrectly states that r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Relevance                                        Explanation\n",
       "93    NON_RELEVANT  The generated answer lists channels that are n...\n",
       "234   NON_RELEVANT  The original answer discusses how brand loyalt...\n",
       "266   NON_RELEVANT  The generated answer lists types of consumer i...\n",
       "632   NON_RELEVANT  The generated answer does not address the ques...\n",
       "816   NON_RELEVANT  The generated answer incorrectly states that a...\n",
       "902   NON_RELEVANT  The generated answer does not address the quer...\n",
       "904   NON_RELEVANT  The generated answer incorrectly states that r...\n",
       "1299  NON_RELEVANT  The generated answer does not address the ques..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_llama8b[df_evaluations_llama8b.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c826be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_llama8b.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-llama8b-aqa.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e30bb2",
   "metadata": {},
   "source": [
    "### Eval Llama 70b responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f69e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the context, syndicated research enta...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Can you explain what syndicated research entails?</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.952520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>According to the context, syndicated research ...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>What type of data is included in syndicated re...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.830384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the provided context, the researc...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>Who compiles the findings for syndicated resea...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.674782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the CONTEXT, syndicated research is c...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>In what industries is syndicated research comm...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.805541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the context, syndicated research ...</td>\n",
       "      <td>Syndicated research is a type of market resear...</td>\n",
       "      <td>3e72e1c8</td>\n",
       "      <td>How can syndicated research benefit multiple c...</td>\n",
       "      <td>General Information</td>\n",
       "      <td>0.839169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  Based on the context, syndicated research enta...   \n",
       "1  According to the context, syndicated research ...   \n",
       "2  According to the provided context, the researc...   \n",
       "3  Based on the CONTEXT, syndicated research is c...   \n",
       "4  According to the context, syndicated research ...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "1  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "2  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "3  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "4  Syndicated research is a type of market resear...  3e72e1c8   \n",
       "\n",
       "                                            question             category  \\\n",
       "0  Can you explain what syndicated research entails?  General Information   \n",
       "1  What type of data is included in syndicated re...  General Information   \n",
       "2  Who compiles the findings for syndicated resea...  General Information   \n",
       "3  In what industries is syndicated research comm...  General Information   \n",
       "4  How can syndicated research benefit multiple c...  General Information   \n",
       "\n",
       "     cosine  \n",
       "0  0.952520  \n",
       "1  0.830384  \n",
       "2  0.674782  \n",
       "3  0.805541  \n",
       "4  0.839169  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-llama70b-cosine.csv'\n",
    "df_llama70b = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df_llama70b.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ea537a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Based on the context, syndicated research entails a type of market research where a research agency collects and compiles data and findings, which are then sold to multiple clients. This research provides broad insights into consumer behavior, market trends, and product performance across various Fast-Moving Consumer Goods (FMCG) categories.', 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'document': '3e72e1c8', 'question': 'Can you explain what syndicated research entails?', 'category': 'General Information', 'cosine': 0.95251954}\n",
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "Generated Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Based on the context, syndicated research entails a type of market research where a research agency collects and compiles data and findings, which are then sold to multiple clients. This research provides broad insights into consumer behavior, market trends, and product performance across various Fast-Moving Consumer Goods (FMCG) categories.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer closely matches the original answer in content and context, accurately explaining what syndicated research entails and highlighting key aspects such as the role of the research agency, the nature of the data collection, and the insights it provides into consumer behavior, market trends, and product performance within the FMCG category.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "samples = df_llama70b.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "print(record)\n",
    "\n",
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "answer = llm(prompt, model='gpt-4o-mini')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e9093ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d9da028f0444e4959f53724c6f6ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "evaluations_llama70b = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_llama70b.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee226cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations_llama70b = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_llama70b):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations_llama70b.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc4154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           987\n",
       "PARTLY_RELEVANT    308\n",
       "NON_RELEVANT         5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_llama70b = pd.DataFrame(json_evaluations_llama70b)\n",
    "df_evaluations_llama70b.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6ed92dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer discusses the frequency o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the orig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer significantly diverges fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide any usef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "189  NON_RELEVANT  The generated answer does not address the role...\n",
       "234  NON_RELEVANT  The generated answer discusses the frequency o...\n",
       "247  NON_RELEVANT  The generated answer does not address the orig...\n",
       "266  NON_RELEVANT  The generated answer significantly diverges fr...\n",
       "961  NON_RELEVANT  The generated answer does not provide any usef..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_llama70b[df_evaluations_llama70b.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "378dd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_llama70b.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-llama70b-aqa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e571f2",
   "metadata": {},
   "source": [
    "# Eval using QA only --- checking relevance of Answer against the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa29e8",
   "metadata": {},
   "source": [
    "### Eval gpt 4o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5ac5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0213087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Can I convert reports into PDF for easy distribution?\n",
      "Generated Answer: Based on the context, the answer to your question is: Yes, you can convert reports into PDF for easy distribution. The FAQ sections mention that reports can be exported in PDF format, and it is possible to export reports as PDFs by selecting the export option in the portal's report viewer.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b9153ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer directly addresses the question by confirming that reports can be converted into PDF for distribution and provides a method for doing so, specifically mentioning the export option in the portal's report viewer. This information is pertinent and useful for the user's request.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edc66da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0106e5ca6e65495c9f4edc828fc26d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations_2 = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt2_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_2.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60172f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "json_evaluations_2 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_2):\n",
    "    try:\n",
    "        # Remove trailing commas before closing braces or brackets\n",
    "        str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations_2.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "        print(f\"Problematic string: {str_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bfe33f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           1233\n",
       "PARTLY_RELEVANT      64\n",
       "NON_RELEVANT          3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_2 = pd.DataFrame(json_evaluations_2)\n",
    "df_evaluations_2.Relevance.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80a953bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-gpt4o-qa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98748b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer states that there is no s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer states that the provided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not directly address...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "93   NON_RELEVANT  The generated answer states that there is no s...\n",
       "189  NON_RELEVANT  The generated answer states that the provided ...\n",
       "983  NON_RELEVANT  The generated answer does not directly address..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_2[df_evaluations_2.Relevance == 'NON_RELEVANT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95adebb-e632-4f49-bee7-dc094ed29eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "938d466d-b0e7-4552-8607-897a5a70e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_samples(samples, prompt_template, model='gpt-4o-mini', llm_func=None):\n",
    "    \"\"\"\n",
    "    Evaluates a list of samples by formatting prompts, passing them through the LLM, and handling JSON decoding.\n",
    "    \n",
    "    Args:\n",
    "    - samples (list of dicts): List of records to be processed.\n",
    "    - prompt_template (str): Template string for formatting the prompt.\n",
    "    - model (str): The LLM model to use (default is 'gpt-4o-mini').\n",
    "    - llm_func (function): Function to call the LLM. Expected signature: llm(prompt, model).\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: DataFrame of JSON-decoded evaluations.\n",
    "    \"\"\"\n",
    "    evaluations = []\n",
    "    \n",
    "    # Generate prompts and get LLM responses\n",
    "    for record in tqdm(samples):\n",
    "        prompt = prompt_template.format(**record)\n",
    "        evaluation = llm_func(prompt, model=model)\n",
    "        evaluations.append(evaluation)\n",
    "\n",
    "    # Convert string responses to JSON, handling any formatting issues\n",
    "    json_evaluations = []\n",
    "    for i, str_eval in enumerate(evaluations):\n",
    "        try:\n",
    "            # Remove trailing commas before closing braces or brackets\n",
    "            str_eval = re.sub(r',\\s*([\\]}])', r'\\1', str_eval)\n",
    "            json_eval = json.loads(str_eval)\n",
    "            json_evaluations.append(json_eval)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON at index {i}: {e}\")\n",
    "            print(f\"Problematic string: {str_eval}\")\n",
    "\n",
    "    # Convert the JSON evaluations into a DataFrame\n",
    "    df_evaluations = pd.DataFrame(json_evaluations)\n",
    "    return df_evaluations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff8401",
   "metadata": {},
   "source": [
    "### Eval gpt 35 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "833728bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Syndicated research entails a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'document': '3e72e1c8', 'question': 'Can you explain what syndicated research entails?', 'category': 'General Information', 'cosine': 0.9809381}\n",
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Syndicated research entails a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer accurately explains the concept of syndicated research, including the process of data collection and the purpose of providing insights to multiple clients. It aligns well with the question asked.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-gpt35-cosine.csv'\n",
    "df_gpt35 = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "samples = df_gpt35.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "print(record)\n",
    "\n",
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "561fdd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1300/1300 [27:13<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "df_evaluations_gpt35_2 = evaluate_samples(samples, prompt_template=prompt2_template, model='gpt-4o-mini', llm_func=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ba4349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance\n",
      "RELEVANT           1162\n",
      "PARTLY_RELEVANT     134\n",
      "NON_RELEVANT          4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer indicates that the FAQ da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer incorrectly states 'No' a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Relevance                                        Explanation\n",
       "232   NON_RELEVANT  The generated answer does not address the ques...\n",
       "536   NON_RELEVANT  The generated answer indicates that the FAQ da...\n",
       "772   NON_RELEVANT  The generated answer incorrectly states 'No' a...\n",
       "1254  NON_RELEVANT  The generated answer does not address the ques..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_evaluations_gpt35_2.Relevance.value_counts())\n",
    "\n",
    "df_evaluations_gpt35_2[df_evaluations_gpt35_2.Relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e220e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_gpt35_2.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-gpt35-qa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c44c8c",
   "metadata": {},
   "source": [
    "### Eval llama 8b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d1a07a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Based on the provided context, syndicated research entails a research agency collecting and compiling data and findings, which are then sold to multiple clients, providing insights into consumer behavior, market trends, and product performance across various FMCG categories. In contrast, custom research is tailored to the specific needs of one client, delivering specific answers to particular business questions.', 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'document': '3e72e1c8', 'question': 'Can you explain what syndicated research entails?', 'category': 'General Information', 'cosine': 0.9076309}\n",
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Based on the provided context, syndicated research entails a research agency collecting and compiling data and findings, which are then sold to multiple clients, providing insights into consumer behavior, market trends, and product performance across various FMCG categories. In contrast, custom research is tailored to the specific needs of one client, delivering specific answers to particular business questions.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer accurately explains what syndicated research entails, detailing its definition, the process involved, and how it differs from custom research. It provides relevant insights into the purpose and application of syndicated research, aligning well with the question asked.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-llama8b-cosine.csv'\n",
    "df_llama8b = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "samples = df_llama8b.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "print(record)\n",
    "\n",
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbcd4903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1300/1300 [27:32<00:00,  1.27s/it] \n"
     ]
    }
   ],
   "source": [
    "df_evaluations_llama8b_2 = evaluate_samples(samples, \n",
    "                                            prompt_template=prompt2_template, \n",
    "                                            model='gpt-4o-mini', \n",
    "                                            llm_func=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d979185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance\n",
      "RELEVANT           1207\n",
      "PARTLY_RELEVANT      92\n",
      "NON_RELEVANT          1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not directly address...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "961  NON_RELEVANT  The generated answer does not directly address..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_evaluations_llama8b_2.Relevance.value_counts())\n",
    "\n",
    "df_evaluations_llama8b_2[df_evaluations_llama8b_2.Relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38828e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_llama8b_2.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-llama8b-qa.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3766f0c6",
   "metadata": {},
   "source": [
    "### Eval llama 70b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a5672bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Based on the context, syndicated research entails a type of market research where a research agency collects and compiles data and findings, which are then sold to multiple clients. This research provides broad insights into consumer behavior, market trends, and product performance across various Fast-Moving Consumer Goods (FMCG) categories.', 'answer_orig': 'Syndicated research is a type of market research where data and findings are collected and compiled by a research agency and then sold to multiple clients. It provides insights into consumer behavior, market trends, and product performance across various FMCG categories.', 'document': '3e72e1c8', 'question': 'Can you explain what syndicated research entails?', 'category': 'General Information', 'cosine': 0.95251954}\n",
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Can you explain what syndicated research entails?\n",
      "Generated Answer: Based on the context, syndicated research entails a type of market research where a research agency collects and compiles data and findings, which are then sold to multiple clients. This research provides broad insights into consumer behavior, market trends, and product performance across various Fast-Moving Consumer Goods (FMCG) categories.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n",
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer accurately explains the concept of syndicated research by describing it as a type of market research conducted by a research agency. It specifies that the data collected is sold to multiple clients, which aligns well with the definition of syndicated research. Additionally, it provides context regarding the types of insights typically gathered, making the answer comprehensive and directly related to the question.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Load Dataframe to judge\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data from the given path\n",
    "file_path = '/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/results-llama70b-cosine.csv'\n",
    "df_llama70b = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "samples = df_llama70b.to_dict(orient='records')\n",
    "record = samples[0]\n",
    "print(record)\n",
    "\n",
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68e7b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1300/1300 [27:11<00:00,  1.26s/it] \n"
     ]
    }
   ],
   "source": [
    "df_evaluations_llama70b_2 = evaluate_samples(samples, \n",
    "                                             prompt_template=prompt2_template, \n",
    "                                             model='gpt-4o-mini', \n",
    "                                             llm_func=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "785e7067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance\n",
      "RELEVANT           1215\n",
      "PARTLY_RELEVANT      81\n",
      "NON_RELEVANT          4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not provide specific...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "189  NON_RELEVANT  The generated answer does not address the ques...\n",
       "236  NON_RELEVANT  The generated answer does not address the ques...\n",
       "247  NON_RELEVANT  The generated answer does not address the ques...\n",
       "961  NON_RELEVANT  The generated answer does not provide specific..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_evaluations_llama70b_2.Relevance.value_counts())\n",
    "\n",
    "df_evaluations_llama70b_2[df_evaluations_llama70b_2.Relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9dc1a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_llama70b_2.to_csv('/workspaces/Rag_Project_Pod/Evaluation/LLM Evaluation/llm_data/evaluations-llama70b-qa.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
